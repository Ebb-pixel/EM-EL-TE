# ğŸŠâ€â™‚ï¸ Underwater Swimmer Pose Estimation  

![Python](https://img.shields.io/badge/Python-3.9-blue.svg)  
![Framework](https://img.shields.io/badge/OpenMMLab-MMPose%20%7C%20MMDetection-green)  
![Torch](https://img.shields.io/badge/PyTorch-2.0-red)  

A two-stage pipeline for **underwater swimmer pose estimation**:  

1. **Detection** â€“ An `RTMDet` model detects the swimmer in each frame.  
2. **Pose Estimation** â€“ The cropped bounding box is passed to an `RTMPose` model to predict keypoints.  

Outputs:  
- ğŸ¥ Annotated video with skeleton overlay.  
- ğŸ“„ JSON file containing keypoint coordinates per frame.  

---

## ğŸ“‚ Repository Structure

rtmpose_annotation/
â”‚
â”œâ”€â”€ training/ # Training configs
â”‚ â””â”€â”€ configs/
â”‚ â”œâ”€â”€ rtmdet_underwater/
â”‚ â”‚ â””â”€â”€ rtmdet_tiny_1class_underwater.py
â”‚ â””â”€â”€ underwater/
â”‚ â”œâ”€â”€ rtmpose-l_underwater.py
â”‚ â””â”€â”€ rtmpose-m_underwater.py
â”‚
â”œâ”€â”€ inference/ # Inference scripts
â”‚ â”œâ”€â”€ configs/ # Flattened configs for standalone inference
â”‚ â”‚ â”œâ”€â”€ rtmdet_tiny_infer_flat.py
â”‚ â”‚ â””â”€â”€ rtmpose-l_infer_flat.py
â”‚ â”œâ”€â”€ custom_inference.py # CLI inference
â”‚ â”œâ”€â”€ gui_inference.py # GUI inference (file chooser + progress)
â”‚ â””â”€â”€ tools/
â”‚ â””â”€â”€ prepare_inference_configs.py
â”‚
â”œâ”€â”€ Dataset_split_script/ # Dataset preparation helpers
â”‚ â”œâ”€â”€ split_coco_person_detection.py
â”‚ â””â”€â”€ split_data.py
â”‚
â””â”€â”€ .gitignore


---

## âš™ï¸ Installation

```bash
# 1. Create conda env
conda create -n mmpose python=3.9 -y
conda activate mmpose

# 2. Install PyTorch (adjust CUDA version if needed)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 3. Clone and install MMDetection
git clone https://github.com/open-mmlab/mmdetection.git
cd mmdetection
pip install -e .
cd ..

# 4. Clone and install MMPose
git clone https://github.com/open-mmlab/mmpose.git
cd mmpose
pip install -e .
cd ..

# 5. Extra requirements
pip install -r requirements.txt

ğŸ“Œ Config Inheritance âš ï¸

The training configs here (e.g. rtmpose-l_underwater.py) inherit from _base_ configs inside the official repos (mmpose/configs and mmdetection/configs).

That means:

âœ… You MUST clone MMPose and MMDetection repos.

âŒ If you only copy configs without repos, training will fail with:

FileNotFoundError: Cannot find config file: ../_base_/models/...

ğŸš€ Training
1ï¸âƒ£ Train RTMDet (Swimmer Detector)

python tools/train.py training/configs/rtmdet_underwater/rtmdet_tiny_1class_underwater.py

2ï¸âƒ£ Train RTMPose (Pose Estimator)

python tools/train.py training/configs/underwater/rtmpose-l_underwater.py

Checkpoints and logs â†’ work_dirs/.

ğŸ¯ Inference
ğŸ”¹ CLI Inference

python inference/custom_inference.py --input path/to/video.mp4 --device cuda

Outputs:

output/result.mp4 â€“ annotated video

output/keypoints.json â€“ keypoint coordinates

ğŸ”¹ GUI Inference

For end-users (double-click .exe or run Python):

File chooser opens to select video.

Progress bar shows during processing.

Notification when inference is done.

python inference/gui_inference.py

ğŸ“Š Dataset Preparation

Use provided scripts:

# Split into train / val / test
python Dataset_split_script/split_data.py

# Filter COCO person annotations
python Dataset_split_script/split_coco_person_detection.py

ğŸ“ Notes

Detector: RTMDet-Tiny (1-class swimmer).

Pose Estimator: RTMPose-L (custom-trained).

Outputs: video + JSON.

For client delivery: packaged as PyInstaller .exe (gui_inference.py).

ğŸ™Œ Credits

MMPose

MMDetection

Dataset collected & annotated for this project - Aquatics GB